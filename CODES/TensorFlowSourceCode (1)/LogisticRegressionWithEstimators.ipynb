{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_goog_sp500_dataframe():\n",
    "  \"\"\"Returns a dataframe with the results for Google and S&P 500\"\"\"\n",
    "  \n",
    "  # Point to where you've stored the CSV file on your local machine\n",
    "  googFile = 'data/GOOG.csv'\n",
    "  spFile = 'data/SP_500.csv'\n",
    "\n",
    "  goog = pd.read_csv(googFile, sep=\",\", usecols=[0,5], names=['Date','Goog'], header=0)\n",
    "  sp = pd.read_csv(spFile, sep=\",\", usecols=[0,5], names=['Date','SP500'], header=0)\n",
    "\n",
    "  goog['SP500'] = sp['SP500']\n",
    "\n",
    "  # The date object is a string, format it as a date\n",
    "  goog['Date'] = pd.to_datetime(goog['Date'], format='%Y-%m-%d')\n",
    "\n",
    "  goog = goog.sort_values(['Date'], ascending=[True])\n",
    "\n",
    "  returns = goog[[key for key in dict(goog.dtypes) if dict(goog.dtypes)[key] in ['float64', 'int64']]]\\\n",
    "            .pct_change()\n",
    "\n",
    "  return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_goog_sp500_logistic_data():\n",
    "  \"\"\"Returns a dataframe with the results for Google and \n",
    "  S&P 500 set up for logistic regression\"\"\"\n",
    "  returns = read_goog_sp500_dataframe()\n",
    "\n",
    "  returns['Intercept'] = 1\n",
    "\n",
    "  # Leave out the first row since it will not have a prediction for UP/DOWN\n",
    "  # Leave out the last row as it will not have a value for returns\n",
    "  # Resultant dataframe with the S&P500 and intercept values of all 1s\n",
    "  xData = np.array(returns[[\"SP500\", \"Intercept\"]][1:-1])\n",
    "\n",
    "  yData = (returns[\"Goog\"] > 0)[1:-1]\n",
    "\n",
    "  return (xData, yData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_goog_sp500_data():\n",
    "  \"\"\"Returns a tuple with 2 fields, the returns for Google and the S&P 500.\n",
    "  Each of the returns are in the form of a 1D array\"\"\"\n",
    "\n",
    "  returns = read_goog_sp500_dataframe()\n",
    "\n",
    "  # Filter out the very first row which does not have any value for returns\n",
    "  xData = np.array(returns[\"SP500\"])[1:]\n",
    "  yData = np.array(returns[\"Goog\"])[1:]\n",
    "\n",
    "  return (xData, yData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_xom_oil_nasdaq_data():\n",
    "  \"\"\"Returns a tuple with 3 fields, the returns for Exxon Mobil, Nasdaq and oil prices.\n",
    "  Each of the returns are in the form of a 1D array\"\"\"\n",
    "\n",
    "  def readFile(filename):\n",
    "    # Only read in the date and price at columns 0 and 5\n",
    "    data = pd.read_csv(filename, sep=\",\", usecols=[0, 5], names=['Date', 'Price'], header=0)\n",
    "\n",
    "    # Sort the data in ascending order of date so returns can be calculated\n",
    "    data['Date'] = pd.to_datetime(data['Date'], format='%Y-%m-%d')\n",
    "\n",
    "    data = data.sort_values(['Date'], ascending=[True])\n",
    "\n",
    "    # Exclude the date from the percentage change calculation\n",
    "    returns = data[[key for key in dict(data.dtypes) if dict(data.dtypes)[key] in ['float64', 'int64']]]\\\n",
    "              .pct_change()\n",
    "\n",
    "    # Filter out the very first row which has no returns associated with it\n",
    "    return np.array(returns[\"Price\"])[1:]\n",
    "\n",
    "  nasdaqData = readFile('data/NASDAQ.csv')\n",
    "  oilData = readFile('data/USO.csv')\n",
    "  xomData = readFile('data/XOM.csv')\n",
    "\n",
    "  return (nasdaqData, oilData, xomData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xData, yData = read_goog_sp500_logistic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit = sm.Logit(yData, xData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.540704\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# Fit the Logistic model\n",
    "result = logit.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All values >0.5 predict an up day for Google\n",
    "predictions = (result.predict(xData) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count the number of times the actual up days match the predicted up days\n",
    "num_accurate_predictions = (list(yData == predictions)).count(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pctAccuracy = float(num_accurate_predictions) / float(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.728\n"
     ]
    }
   ],
   "source": [
    "print \"Accuracy: \", pctAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic regression with estimators\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [tf.contrib.layers.real_valued_column(\"x\", dimension=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': None, '_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': None, '_environment': 'local', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x121754a10>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_num_worker_replicas': 0, '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': ''}\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/yd/1rlyjfk975d3bb98d7_nyt740000gn/T/tmpG6obAC\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.contrib.learn.LinearClassifier(feature_columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All returns in a 2D array\n",
    "# [[-0.02184618]\n",
    "# [ 0.00997998]\n",
    "# [ 0.04329069]\n",
    "# [ 0.03254923]\n",
    "# [-0.01781632]]\n",
    "x = np.expand_dims(xData[:,0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# True/False values for up/down days in a 2D array\n",
    "# [[False]\n",
    "# [ True]\n",
    "# [ True]\n",
    "# [ True]\n",
    "# [ True]\n",
    "# [False]]\n",
    "y = np.expand_dims(np.array(yData), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Batch size of 100 and 10000 epochs\n",
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\" : x}, y, batch_size=100, num_epochs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/yd/1rlyjfk975d3bb98d7_nyt740000gn/T/tmpG6obAC/model.ckpt-20000\n",
      "INFO:tensorflow:Saving checkpoints for 20001 into /var/folders/yd/1rlyjfk975d3bb98d7_nyt740000gn/T/tmpG6obAC/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.556471, step = 20001\n",
      "INFO:tensorflow:global_step/sec: 663.583\n",
      "INFO:tensorflow:loss = 0.59909, step = 20101 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 687.266\n",
      "INFO:tensorflow:loss = 0.585052, step = 20201 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 685.251\n",
      "INFO:tensorflow:loss = 0.511888, step = 20301 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 753.176\n",
      "INFO:tensorflow:loss = 0.532793, step = 20401 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 721.922\n",
      "INFO:tensorflow:loss = 0.513937, step = 20501 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.272\n",
      "INFO:tensorflow:loss = 0.531995, step = 20601 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 641.622\n",
      "INFO:tensorflow:loss = 0.492279, step = 20701 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 640.906\n",
      "INFO:tensorflow:loss = 0.580781, step = 20801 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 648.626\n",
      "INFO:tensorflow:loss = 0.53989, step = 20901 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 637.069\n",
      "INFO:tensorflow:loss = 0.566952, step = 21001 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 673.931\n",
      "INFO:tensorflow:loss = 0.534752, step = 21101 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.508\n",
      "INFO:tensorflow:loss = 0.46751, step = 21201 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 627.55\n",
      "INFO:tensorflow:loss = 0.558093, step = 21301 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 637.34\n",
      "INFO:tensorflow:loss = 0.583586, step = 21401 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 570.936\n",
      "INFO:tensorflow:loss = 0.480483, step = 21501 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 609.693\n",
      "INFO:tensorflow:loss = 0.53559, step = 21601 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 616.899\n",
      "INFO:tensorflow:loss = 0.531685, step = 21701 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 680.438\n",
      "INFO:tensorflow:loss = 0.541377, step = 21801 (0.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 698.09\n",
      "INFO:tensorflow:loss = 0.513099, step = 21901 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 630.128\n",
      "INFO:tensorflow:loss = 0.52774, step = 22001 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 713.939\n",
      "INFO:tensorflow:loss = 0.53199, step = 22101 (0.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 567.924\n",
      "INFO:tensorflow:loss = 0.53157, step = 22201 (0.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 669.734\n",
      "INFO:tensorflow:loss = 0.560422, step = 22301 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 722.826\n",
      "INFO:tensorflow:loss = 0.593139, step = 22401 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 731.518\n",
      "INFO:tensorflow:loss = 0.529019, step = 22501 (0.136 sec)\n",
      "INFO:tensorflow:global_step/sec: 723.746\n",
      "INFO:tensorflow:loss = 0.634094, step = 22601 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.619\n",
      "INFO:tensorflow:loss = 0.519168, step = 22701 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 643.294\n",
      "INFO:tensorflow:loss = 0.541309, step = 22801 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 615.391\n",
      "INFO:tensorflow:loss = 0.507487, step = 22901 (0.163 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.446\n",
      "INFO:tensorflow:loss = 0.482051, step = 23001 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 702.879\n",
      "INFO:tensorflow:loss = 0.580921, step = 23101 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 713.252\n",
      "INFO:tensorflow:loss = 0.545417, step = 23201 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 635.946\n",
      "INFO:tensorflow:loss = 0.502315, step = 23301 (0.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 574.369\n",
      "INFO:tensorflow:loss = 0.491094, step = 23401 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 561.726\n",
      "INFO:tensorflow:loss = 0.506754, step = 23501 (0.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 593.655\n",
      "INFO:tensorflow:loss = 0.57887, step = 23601 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 775.759\n",
      "INFO:tensorflow:loss = 0.591758, step = 23701 (0.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 625.731\n",
      "INFO:tensorflow:loss = 0.548103, step = 23801 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 554.909\n",
      "INFO:tensorflow:loss = 0.510303, step = 23901 (0.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 596.932\n",
      "INFO:tensorflow:loss = 0.565598, step = 24001 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 585.265\n",
      "INFO:tensorflow:loss = 0.53932, step = 24101 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 598.63\n",
      "INFO:tensorflow:loss = 0.527095, step = 24201 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.613\n",
      "INFO:tensorflow:loss = 0.492275, step = 24301 (0.154 sec)\n",
      "INFO:tensorflow:global_step/sec: 634.036\n",
      "INFO:tensorflow:loss = 0.554241, step = 24401 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 729.235\n",
      "INFO:tensorflow:loss = 0.585887, step = 24501 (0.138 sec)\n",
      "INFO:tensorflow:global_step/sec: 631.672\n",
      "INFO:tensorflow:loss = 0.527111, step = 24601 (0.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 665.15\n",
      "INFO:tensorflow:loss = 0.555775, step = 24701 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 531.445\n",
      "INFO:tensorflow:loss = 0.522578, step = 24801 (0.188 sec)\n",
      "INFO:tensorflow:global_step/sec: 615.423\n",
      "INFO:tensorflow:loss = 0.609618, step = 24901 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 644.022\n",
      "INFO:tensorflow:loss = 0.540507, step = 25001 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 675.251\n",
      "INFO:tensorflow:loss = 0.570938, step = 25101 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 597.668\n",
      "INFO:tensorflow:loss = 0.471906, step = 25201 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 584.785\n",
      "INFO:tensorflow:loss = 0.511633, step = 25301 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 607.172\n",
      "INFO:tensorflow:loss = 0.534218, step = 25401 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 585.24\n",
      "INFO:tensorflow:loss = 0.613109, step = 25501 (0.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 754.592\n",
      "INFO:tensorflow:loss = 0.535181, step = 25601 (0.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 575.503\n",
      "INFO:tensorflow:loss = 0.580511, step = 25701 (0.173 sec)\n",
      "INFO:tensorflow:global_step/sec: 697.973\n",
      "INFO:tensorflow:loss = 0.506351, step = 25801 (0.144 sec)\n",
      "INFO:tensorflow:global_step/sec: 657.968\n",
      "INFO:tensorflow:loss = 0.56689, step = 25901 (0.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 613.452\n",
      "INFO:tensorflow:loss = 0.5865, step = 26001 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 605.517\n",
      "INFO:tensorflow:loss = 0.516652, step = 26101 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 661.954\n",
      "INFO:tensorflow:loss = 0.498355, step = 26201 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 670.205\n",
      "INFO:tensorflow:loss = 0.532231, step = 26301 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 588.526\n",
      "INFO:tensorflow:loss = 0.551359, step = 26401 (0.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 779.41\n",
      "INFO:tensorflow:loss = 0.512912, step = 26501 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 593.79\n",
      "INFO:tensorflow:loss = 0.571514, step = 26601 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 574.204\n",
      "INFO:tensorflow:loss = 0.527479, step = 26701 (0.174 sec)\n",
      "INFO:tensorflow:global_step/sec: 652.17\n",
      "INFO:tensorflow:loss = 0.518187, step = 26801 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 679.63\n",
      "INFO:tensorflow:loss = 0.607975, step = 26901 (0.148 sec)\n",
      "INFO:tensorflow:global_step/sec: 582.418\n",
      "INFO:tensorflow:loss = 0.513438, step = 27001 (0.171 sec)\n",
      "INFO:tensorflow:global_step/sec: 699.663\n",
      "INFO:tensorflow:loss = 0.463242, step = 27101 (0.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 655.454\n",
      "INFO:tensorflow:loss = 0.503861, step = 27201 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 668.333\n",
      "INFO:tensorflow:loss = 0.513126, step = 27301 (0.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 661.954\n",
      "INFO:tensorflow:loss = 0.510789, step = 27401 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 698.665\n",
      "INFO:tensorflow:loss = 0.607071, step = 27501 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 791.496\n",
      "INFO:tensorflow:loss = 0.506965, step = 27601 (0.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 601.641\n",
      "INFO:tensorflow:loss = 0.514859, step = 27701 (0.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 778.187\n",
      "INFO:tensorflow:loss = 0.544784, step = 27801 (0.128 sec)\n",
      "INFO:tensorflow:global_step/sec: 641.293\n",
      "INFO:tensorflow:loss = 0.50643, step = 27901 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 632.259\n",
      "INFO:tensorflow:loss = 0.612123, step = 28001 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 631.9\n",
      "INFO:tensorflow:loss = 0.529616, step = 28101 (0.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 743.92\n",
      "INFO:tensorflow:loss = 0.57286, step = 28201 (0.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 617.059\n",
      "INFO:tensorflow:loss = 0.542306, step = 28301 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 650.682\n",
      "INFO:tensorflow:loss = 0.496521, step = 28401 (0.153 sec)\n",
      "INFO:tensorflow:global_step/sec: 688.202\n",
      "INFO:tensorflow:loss = 0.574038, step = 28501 (0.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 714.057\n",
      "INFO:tensorflow:loss = 0.50566, step = 28601 (0.139 sec)\n",
      "INFO:tensorflow:global_step/sec: 704.504\n",
      "INFO:tensorflow:loss = 0.498726, step = 28701 (0.142 sec)\n",
      "INFO:tensorflow:global_step/sec: 668.261\n",
      "INFO:tensorflow:loss = 0.505002, step = 28801 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 617.52\n",
      "INFO:tensorflow:loss = 0.56514, step = 28901 (0.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 593.183\n",
      "INFO:tensorflow:loss = 0.510074, step = 29001 (0.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 629.303\n",
      "INFO:tensorflow:loss = 0.533899, step = 29101 (0.159 sec)\n",
      "INFO:tensorflow:global_step/sec: 692.727\n",
      "INFO:tensorflow:loss = 0.588943, step = 29201 (0.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 661.91\n",
      "INFO:tensorflow:loss = 0.575164, step = 29301 (0.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 702.104\n",
      "INFO:tensorflow:loss = 0.566861, step = 29401 (0.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 646.936\n",
      "INFO:tensorflow:loss = 0.489507, step = 29501 (0.155 sec)\n",
      "INFO:tensorflow:global_step/sec: 670.057\n",
      "INFO:tensorflow:loss = 0.524084, step = 29601 (0.149 sec)\n",
      "INFO:tensorflow:global_step/sec: 774.155\n",
      "INFO:tensorflow:loss = 0.597931, step = 29701 (0.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 608.12\n",
      "INFO:tensorflow:loss = 0.548483, step = 29801 (0.165 sec)\n",
      "INFO:tensorflow:global_step/sec: 461.195\n",
      "INFO:tensorflow:loss = 0.537301, step = 29901 (0.218 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 30000 into /var/folders/yd/1rlyjfk975d3bb98d7_nyt740000gn/T/tmpG6obAC/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.518041.\n"
     ]
    }
   ],
   "source": [
    "fit = estimator.fit(input_fn=input_fn, steps=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# All data points in a single batch with just one epoch\n",
    "input_fn_oneshot = tf.contrib.learn.io.numpy_input_fn({\"x\": x }, y, batch_size=len(x), num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-07-10-11:35:41\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/yd/1rlyjfk975d3bb98d7_nyt740000gn/T/tmpG6obAC/model.ckpt-30000\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-07-10-11:35:42\n",
      "INFO:tensorflow:Saving dict for global step 30000: accuracy = 0.72, accuracy/baseline_label_mean = 0.576, accuracy/threshold_0.500000_mean = 0.72, auc = 0.794156, global_step = 30000, labels/actual_label_mean = 0.576, labels/prediction_mean = 0.576088, loss = 0.542261, precision/positive_threshold_0.500000_mean = 0.717647, recall/positive_threshold_0.500000_mean = 0.847222\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n"
     ]
    }
   ],
   "source": [
    "results = fit.evaluate(input_fn=input_fn_oneshot, steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy/baseline_label_mean': 0.57599998, 'loss': 0.54226089, 'auc': 0.79415619, 'global_step': 30000, 'accuracy/threshold_0.500000_mean': 0.72000003, 'recall/positive_threshold_0.500000_mean': 0.84722221, 'labels/prediction_mean': 0.57608789, 'accuracy': 0.72000003, 'precision/positive_threshold_0.500000_mean': 0.71764708, 'labels/actual_label_mean': 0.57599998}\n"
     ]
    }
   ],
   "source": [
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_step  --->  30000\n",
      "linear/bias_weight  --->  [ 0.1922386]\n",
      "linear/bias_weight/d/linear/bias_weight/part_0/Ftrl  --->  [ 54.64965439]\n",
      "linear/bias_weight/d/linear/bias_weight/part_0/Ftrl_1  --->  [-7.10565758]\n",
      "linear/x/weight  --->  [[ 28.59745598]]\n",
      "linear/x/weight/head/linear/x/weight/part_0/Ftrl  --->  [[ 0.50103468]]\n",
      "linear/x/weight/head/linear/x/weight/part_0/Ftrl_1  --->  [[-101.21183777]]\n"
     ]
    }
   ],
   "source": [
    "for variable_name in fit.get_variable_names():\n",
    "    print variable_name , \" ---> \" , fit.get_variable_value(variable_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
